{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgCS09MxtzMm",
        "outputId": "13810a28-a8f0-4d56-b84d-a30c927485e7"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKZQyHDZzEgD"
      },
      "source": [
        "**Note:** Set **\"drive_path\"** according to your folder location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH1S_pTwVjZx",
        "outputId": "8960efab-6728-4a2b-8654-7450e97b3e41"
      },
      "source": [
        "!pip install -U torchtext==0.8.0\n",
        "!pip install torch==1.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed torchtext-0.8.0\n",
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |█████████████████               | 415.2MB 1.3MB/s eta 0:04:34"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khWlP10M5-Ma",
        "outputId": "ac8dfb23-f66c-4ba0-a480-8a0f608dd1a7"
      },
      "source": [
        "'''\n",
        "    /*----------------------------- MOUNT_GOOGLE_DRIVE -------------\n",
        "      - To connect your colab notebook with google drive\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyCeSihRVjJY"
      },
      "source": [
        "drive_path = '/content/drive/My Drive/ner/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9gFROU5vI8d"
      },
      "source": [
        "# **Steps – NER using LSTM**\n",
        "* **Step 1: Import Libraries**\n",
        "* **Step 2: Load Training Data, Testing Data and Validation Data**\n",
        "* **Step 3: Understand and Pre-process Training Data, Testing Data and  Validation Data**\n",
        "* **Step 4: Represent Training Data, Testing Data and Validation Data in Machine Understandable Format**\n",
        "* **Step 5: Execute the Training and Validation Phase**\n",
        "* **Step 6: Execute the Testing Phase**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEc01RbkwsGw"
      },
      "source": [
        "# **Step 1: Import Libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gReWlANUTmTA"
      },
      "source": [
        "'''\n",
        "    /*----------------------------- IMPORT_LIBRARIES -------------\n",
        "'''\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "from torchtext import vocab\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data import Field\n",
        "from torch.autograd import Variable\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.data import TabularDataset\n",
        "device = torch.device(\"cuda:0\")\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnJDaQ66uxtS"
      },
      "source": [
        "# **Step 2: Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdXXhRJ5FR2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "ea14ac94-d67b-402c-8915-b9fefb7c6ab6"
      },
      "source": [
        "data_ = pd.read_csv(drive_path + \"ner_dataset.csv\", encoding=\"latin1\")\n",
        "data_ = data_.drop(['POS'], axis =1)\n",
        "data_ = data_.fillna(method=\"ffill\")\n",
        "data_.head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word    Tag\n",
              "0  Sentence: 1      Thousands      O\n",
              "1  Sentence: 1             of      O\n",
              "2  Sentence: 1  demonstrators      O\n",
              "3  Sentence: 1           have      O\n",
              "4  Sentence: 1        marched      O\n",
              "5  Sentence: 1        through      O\n",
              "6  Sentence: 1         London  B-geo\n",
              "7  Sentence: 1             to      O\n",
              "8  Sentence: 1        protest      O\n",
              "9  Sentence: 1            the      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_fYtc0yvULV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c089f1-4ee2-42db-bcd5-82fc9899ab55"
      },
      "source": [
        "words = set(list(data_['Word'].values))\n",
        "print(len(words))\n",
        "words.add('PADword')\n",
        "n_words = len(words)\n",
        "n_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HefI8H9ZvT-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1d1170-9fb5-4b07-b899-bbfa0288fb81"
      },
      "source": [
        "tags = list(set(data_[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "n_tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcZnQNZ8vTiK"
      },
      "source": [
        "class SentenceGetter(object):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT6p5gIZvchu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cb6e41-fa72-451a-f6a2-df2a3e81c54f"
      },
      "source": [
        "getter = SentenceGetter(data_)\n",
        "sent = getter.get_next()\n",
        "print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ3uGaNFvcUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5d80cd-ed91-499d-c476-9d446f87427d"
      },
      "source": [
        "sentences = getter.sentences\n",
        "print(len(sentences))\n",
        "largest_sen = max(len(sen) for sen in sentences)\n",
        "print('biggest sentence has {} words'.format(largest_sen))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47959\n",
            "biggest sentence has 104 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEzi5-ZYvcF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e3bf03c1-136b-453a-a6f6-12495a340c58"
      },
      "source": [
        "%matplotlib inline\n",
        "plt.hist([len(sen) for sen in sentences], bins= 50)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcEuWNOXv0fc"
      },
      "source": [
        "X = [[w[0]for w in s] for s in sentences]\n",
        "y = [[w[1] for w in s] for s in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNQmN_Rhv0Qt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, random_state=2018)\n",
        "batch_size = 32\n",
        "X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\n",
        "y_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTbOXxTdv0CI"
      },
      "source": [
        "train_data_X = [\" \".join(z) for z in X_tr]\n",
        "train_data_y = [\" \".join(z) for z in y_tr]\n",
        "test_data_X = [\" \".join(z) for z in X_te]\n",
        "test_data_y = [\" \".join(z) for z in y_te]\n",
        "valid_data_X = [\" \".join(z) for z in X_val]\n",
        "valid_data_y = [\" \".join(z) for z in y_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srRYaQO3vzzh"
      },
      "source": [
        "train_data_X = pd.DataFrame(train_data_X)\n",
        "train_data_y = pd.DataFrame(train_data_y)\n",
        "train_data = pd.concat([train_data_X,train_data_y],axis =1)\n",
        "train_data.columns = [\"sentence\",\"tags\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5SudVHCvzlh"
      },
      "source": [
        "test_data_X = pd.DataFrame(test_data_X)\n",
        "test_data_y = pd.DataFrame(test_data_y)\n",
        "test_data = pd.concat([test_data_X,test_data_y],axis =1)\n",
        "test_data.columns = [\"sentence\",\"tags\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gcXSXUmwVB7"
      },
      "source": [
        "valid_data_X = pd.DataFrame(valid_data_X)\n",
        "valid_data_y = pd.DataFrame(valid_data_y)\n",
        "valid_data = pd.concat([valid_data_X,valid_data_y],axis =1)\n",
        "valid_data.columns = [\"sentence\",\"tags\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNS9Z_b2wb21"
      },
      "source": [
        "train_data.to_csv(\"train_data.csv\",index=None)\n",
        "test_data.to_csv(\"test_data.csv\",index=None)\n",
        "valid_data.to_csv(\"valid_data.csv\",index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKfd525Swy2g"
      },
      "source": [
        "# **Step 3: Load Training Data, Testing Data and Validation Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkqrZtTk-b3w"
      },
      "source": [
        "def load_dataset(drive_path, dataset):\n",
        "  loaded_dataset = pd.read_csv(drive_path + dataset)     # Read CSV file\n",
        "  print(\"=\"*40, \"\\n\", loaded_dataset)                    # Print the dataset that we load in previous step\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWzDT9n4JwE1"
      },
      "source": [
        "# **Step 4: Understand and Pre-process Training Data, Testing Data and Validation Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNjSqTfyDWJ-"
      },
      "source": [
        "### **Step 4.1: Tokenize Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Gls9kjKnZt"
      },
      "source": [
        "def data_tokenization(s):\n",
        "  return s.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psc4OejpNdTK"
      },
      "source": [
        "### **Step 4.2: Build Training Data, Testing Data and Validation Data Objects**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QbnDKWrKxbj"
      },
      "source": [
        "def data_objects(drive_path):\n",
        "  # Declared a Field object\n",
        "  # Field : A class that stores information about the way of preprocessing\n",
        "  TEXT  = Field(sequential= True, tokenize = data_tokenization, lower = True, batch_first = False, fix_length=40,pad_token='<pad>')\n",
        "  LABEL  = Field(tokenize = data_tokenization, batch_first = False,fix_length=40,pad_token='O')\n",
        "  #LABEL = data.LabelField(dtype = torch.long)\n",
        "  # TabularDataset : Defines a dataset of columns. Create a TabularDataset given a path, file format,\n",
        "  # and Field list\n",
        "  training_data, validation_data, testing_data = TabularDataset.splits(path = drive_path,\n",
        "                                                            train       = 'train_data.csv',\n",
        "                                                            validation  = 'valid_data.csv',\n",
        "                                                            test        = 'test_data.csv',\n",
        "                                                            format      = 'csv',\n",
        "                                                            fields      = [('sentence', TEXT),('tags', LABEL)],\n",
        "                                                            skip_header = True)\n",
        "\n",
        "\n",
        "  return training_data, validation_data, testing_data, LABEL, TEXT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9AeRKT7N_Ak"
      },
      "source": [
        "### **Step 4.3: Load Pre-Trained Word Embedding Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMh7-DNUMaTP"
      },
      "source": [
        "def load_word_embedding_vectors(drive_path):\n",
        "  # Load word embedding vectors from memory\n",
        "  # I have downloaded the Glove word embedding vectors 100d from internet and saved in my drive\n",
        "  # To use that, I simply give the path of that file and read file in my program using vocab.Vectors function\n",
        "  vectors = vocab.Vectors('glove.6B.100d.txt', drive_path)\n",
        "  return vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2xwroDYROvr"
      },
      "source": [
        "### **Step 4.4: Build Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVCVnAdaQWVh"
      },
      "source": [
        "def build_vocabulary(training_data, validation_data , testing_data, vectors, LABEL, TEXT):\n",
        "  # Note: Best practice when working with real world dataset build vocabulary only on Training Data\n",
        "  TEXT.build_vocab(training_data, validation_data , testing_data, vectors=vectors, unk_init=torch.Tensor.normal_)   # Build vocabulary from input text\n",
        "  LABEL.build_vocab(training_data, validation_data , testing_data)                   # Build vocabulary from output / labels (Encode all labels)\n",
        "\n",
        "  print(\"\\n=========================================\")\n",
        "  print(\"Output/Label word to index dictionary: \", LABEL.vocab.stoi)\n",
        "  print(\"\\n=========================================\")\n",
        "  print(\"Input Text word to index dictionary:\\n \", TEXT.vocab.stoi,\"\\n\")\n",
        "\n",
        "  word_embeddings = TEXT.vocab.vectors   # Load vectors\n",
        "  vocabulary_size = len(TEXT.vocab)      # Size of vocabulary\n",
        "  return word_embeddings, vocabulary_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O1Rf_hqGrTA"
      },
      "source": [
        "# **Step 5: Represent Training Data, Testing Data and Validation Data in Machine Understandable Format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4g4KhoqPAPV"
      },
      "source": [
        "def data_iterators(training_data, validation_data, testing_data):\n",
        "  # Iterators handle numericalizing, batching, packaging. Basically, it does all the heavy lifting necessary\n",
        "  # to pass the data to a neural network\n",
        "  # BucketIterator : Defines an iterator that batches examples of similar lengths together to minimizes the amount of padding needed\n",
        "  # By using \"splits\" it applies processing steps on all datasets equally\n",
        "\n",
        "  training_iterator, validation_iterator, testing_iterator = data.BucketIterator.splits((training_data, validation_data, testing_data), batch_size=32, sort_key=lambda x: len(x.sentence), repeat=False, shuffle=False)\n",
        "\n",
        "  return training_iterator, validation_iterator, testing_iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYa50aXBG_iu"
      },
      "source": [
        "print(\"+============================Data Preparation============================+\\n\\n\")\n",
        "\n",
        "print(\"---Step 2: Load Training Data, Testing Data and Validation Data---\")\n",
        "print(\"\\nTraining data\")\n",
        "original_training_data = load_dataset(drive_path,'train_data.csv')\n",
        "print(\"\\nValidation data\")\n",
        "original_training_data = load_dataset(drive_path,'valid_data.csv')\n",
        "print(\"\\nTesting data\")\n",
        "original_training_data = load_dataset(drive_path,'test_data.csv')\n",
        "\n",
        "\n",
        "print(\"\\n---Step 3: Understand and Pre-process Training Data, Testing Data and Validation Data---\")\n",
        "print(\"\\n---Step 4: Represent Training Data, Testing Data and Validation Data in Machine Understandable Format---\")\n",
        "preprocessed_training_data, preprocessed_validation_data, preprocessed_testing_data, LABEL, TEXT = data_objects(drive_path)\n",
        "# Load word embedding vectors from memory\n",
        "vectors = load_word_embedding_vectors(drive_path)\n",
        "# Build vocabulary\n",
        "word_embeddings, vocabulary_size = build_vocabulary(preprocessed_training_data, preprocessed_validation_data, preprocessed_testing_data, vectors, LABEL, TEXT)\n",
        "# Create iterator objects\n",
        "training_iterator, validation_iterator, testing_iterator = data_iterators(preprocessed_training_data, preprocessed_validation_data, preprocessed_testing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA28a28VbwG3"
      },
      "source": [
        "# **Step 6: Execute the Training Phase**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQVos9zwx1lF"
      },
      "source": [
        "### **Step 6.1:Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRSleE1TuGr"
      },
      "source": [
        "\n",
        "'''\n",
        "    /*----------------------------- MODEL_ARCHITECTURE -------------\n",
        "    | Class     : BLSTM()\n",
        "    | Purpose   : To build the architecture of model to be trained\n",
        "    *---------------------------------------------------------\n",
        "    | nn.Module : Base class for all neural network modules. Your models should also subclass this class.\n",
        "    |\n",
        "    | Arguments:\n",
        "    |      output_dim    : 18 (Classes of tags --> 12). For output layer number of nodes in output layer will be same as\n",
        "    |                      number of outputs required in your problem\n",
        "    |\t     hidden_dim    : Size of the hidden layer. Here size of hidden_state of the lstm\n",
        "    | \t\t input_dim     : Size of the vocabulary containing unique words. Total number of unique words in sample data\n",
        "    |\t\t   embedding_dim : Size of each embedding vector. Here embeddding dimension of GloVe word embedding\n",
        "    |                      vectors is 100 so embedding_dim = 100\n",
        "    |\t\t   weights       : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table\n",
        "    *------------------------------------------------------------------------------------\n",
        "    | Function  : forward()\n",
        "    | Purpose   : This function will automatically start foward propogation when model object is called\n",
        "    | Arguments :\n",
        "    |     text  : Input text of shape = (num_sequences, batch_size)\n",
        "\t  | Return:\n",
        "\t  |     hidden_state : Final model state learned from input text\n",
        "    ------------------------------------------------------------------------------\n",
        "'''\n",
        "\n",
        "class BLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, word_embeddings, n_layers, n_directions):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_layers     = n_layers\n",
        "        self.n_directions = n_directions\n",
        "        self.hidden_dim   = hidden_dim\n",
        "        self.embedding_layer = nn.Embedding(input_dim, embedding_dim)          # Embedding layer shape\n",
        "        # Assign pre-trained weights and update the weights during backpropagation\n",
        "        self.embedding_layer.weight = nn.Parameter(word_embeddings, requires_grad = True)\n",
        "        self.blstm_layer       = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = True, dropout = 0.2) # We can implement multiple layers of lstm simply by changing num_layers value\n",
        "        self.linear_layer      = nn.Linear(hidden_dim * 2, output_dim)               # Shape of linear layer\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        batch_size = text.shape[1]\n",
        "        h_0, c_0 = self.init_hidden(batch_size)   # Initialize first hidden state to all zeros\n",
        "\n",
        "        # Here we will map all the indexes present in the input sequence to the corresponding\n",
        "\t\t    # word vector using our trained word_embedddings.\n",
        "\t      # embedded input of shape = (num_sequences, batch_size, embedding_dimension)\n",
        "        embedded_vectors = self.embedding_layer(text)\n",
        "\n",
        "        output_state, (hidden_state, cell_state) = self.blstm_layer(embedded_vectors, (h_0, c_0))  # Apply blstm layer and start learning sequence of words\n",
        "\n",
        "        hidden_state = self.linear_layer(output_state)      # Apply the linear layer on hidden_state / context vector\n",
        "        return hidden_state\n",
        "    def init_hidden(self,batch_size):\n",
        "        h_0 = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_dim)\n",
        "        c_0 = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_dim)\n",
        "        return h_0, c_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvs0X3gGx5mt"
      },
      "source": [
        "### **Step 6.2: Hyperparameters Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CefOUiYxTuLS"
      },
      "source": [
        "'''\n",
        "/*---------------- INITIALIZE_PARAMETERS ------------------\n",
        "'''\n",
        "\n",
        "input_dimension      = len(TEXT.vocab)\n",
        "embedding_dimension  = 100\n",
        "hidden_dimension     = 512\n",
        "output_dimension     = len(LABEL.vocab)\n",
        "number_of_layers     = 2\n",
        "number_of_directions = 2\n",
        "number_of_epochs     = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei0-8uIEyg8S"
      },
      "source": [
        "### **Step 6.3: Create Model Object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q3WynYHydya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f664146-e374-4ded-a2f7-dc36f98b41ae"
      },
      "source": [
        "model = BLSTM(input_dimension, embedding_dimension, hidden_dimension, output_dimension, word_embeddings, number_of_layers, number_of_directions)\n",
        "print(\"\\nModel Architecture\\n==================\\n\")\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model Architecture\n",
            "==================\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BLSTM(\n",
              "  (embedding_layer): Embedding(31813, 100)\n",
              "  (blstm_layer): LSTM(100, 512, num_layers=2, dropout=0.2, bidirectional=True)\n",
              "  (linear_layer): Linear(in_features=1024, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wel_CVE9Hq7h"
      },
      "source": [
        "### **Step 6.4: Initialize Optimizer and Loss Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSnSintDHp-Y"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)   # Initialize the optimizer\n",
        "criterion = nn.CrossEntropyLoss()                     # Intialize loss function (also deals with Softmax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4EbzTf2yDXv"
      },
      "source": [
        "### **Step 6.5: Evaluation Measure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUv7C61bUCxh"
      },
      "source": [
        "def calculate_accuracy(prediction, label):\n",
        "\n",
        "    rounded_preds = (torch.softmax(prediction,dim=1)).argmax(1)                    # Round predictions to the closest integer\n",
        "    accuracy = accuracy_score(label, rounded_preds)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmpfF_Gfr7qq"
      },
      "source": [
        "def calculate_f1(prediction, label):\n",
        "\n",
        "    rounded_preds = (torch.softmax(prediction,dim=1)).argmax(1)                    # Round predictions to the closest integer\n",
        "    f1 = f1_score(label, rounded_preds, average='weighted')\n",
        "\n",
        "\n",
        "    return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NetB7IAkkQBZ"
      },
      "source": [
        "### **Step 6.6: Calculate Epoch Elapsed Time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooQgi4hSkOzY"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time                   # Time elapsed by one epoch\n",
        "    elapsed_mins = int(elapsed_time / 60)                  # Convert time in minutes\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60)) # Convert time in seconds\n",
        "    return elapsed_mins, elapsed_secs, elapsed_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaCrVXFHk3Un"
      },
      "source": [
        "### **Step 6.7: Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCEM1y30UCtn"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss      = 0                                                 # Initialize epoch loss to 0\n",
        "    epoch_accuracy  = 0                                                 # Initialize epoch accuracy to 0\n",
        "\n",
        "    model.train()                                                       # Start model training mode\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        optimizer.zero_grad()                                           # Clear all optimized gradients\n",
        "        text = batch.sentence\n",
        "        predictions = model(text)                # Make model predictions on training data\n",
        "\n",
        "        output_dim = predictions.shape[-1]\n",
        "        predictions = predictions.view(-1, output_dim)\n",
        "\n",
        "        trg = batch.tags.view(-1)\n",
        "\n",
        "        loss     = criterion(predictions, trg)                 # Calculate loss for each batch in epoch\n",
        "\n",
        "        accuracy = calculate_accuracy(predictions, trg)        # Calculate accuracy for each batch in epoch\n",
        "\n",
        "        loss.backward()                                                  # Start backward propogation\n",
        "        optimizer.step()                                                 # Optimization of parameters\n",
        "\n",
        "        epoch_loss      += loss.item()                                   # Add loss for all batches in one epoch\n",
        "        epoch_accuracy  += accuracy.item()                               # Add accuracy for all batches in one epoch\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)    # Average loss and accuracy for one epoch and return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkJM892QCf8n"
      },
      "source": [
        "### **Step 6.8: Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs2t_LSsCflh"
      },
      "source": [
        "def save_model(drive_path):\n",
        "  torch.save(model.state_dict(), drive_path + 'best-lstm-model.pt')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnUl6WU3mqN8"
      },
      "source": [
        "### **6.9 Evaluate Model**\n",
        "\n",
        "\n",
        "*   **Function to be used in Validation and Test Phase**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xu03MMmmsHS"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss     = 0      # Initialize epoch loss to 0\n",
        "    epoch_accuracy = 0      # Initialize epoch accuracy to 0\n",
        "    epoch_f1 = 0\n",
        "    model.eval()            # Start model evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "\n",
        "            text = batch.sentence\n",
        "            predictions = model(text)                # Make model predictions on data\n",
        "            #loss = criterion(predictions, batch.tags)               # Calculate loss for each batch in epoch\n",
        "\n",
        "            output_dim = predictions.shape[-1]\n",
        "            predictions = predictions.view(-1, output_dim)\n",
        "\n",
        "            trg = batch.tags.view(-1)\n",
        "\n",
        "            loss     = criterion(predictions, trg)                 # Calculate loss for each batch in epoch\n",
        "\n",
        "            accuracy = calculate_accuracy(predictions, trg)  # Calculate accuracy for each batch in epoch\n",
        "\n",
        "            epoch_loss += loss.item()                                 # Add loss for all batches, in one epoch\n",
        "            epoch_accuracy += accuracy.item()                         # Add accuracy for all batches in one epoch\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)  # Average loss and accuracy for one epoch and return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNviSRgznIRm"
      },
      "source": [
        "# **Step 7: Execute the Validation Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m7Zgk3PnHAp"
      },
      "source": [
        "def validation(model, validation_iterator, criterion):\n",
        "      best_validation_loss = float('inf')                                                        # Declare best validation loss variable\n",
        "      validation_loss, validation_accuracy = evaluate(model, validation_iterator, criterion)     # Start model validation phase\n",
        "\n",
        "      if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        save_model(drive_path)                                   # Save model on epoch where the validation loss is lowest\n",
        "      return validation_loss, validation_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzg9CAIO7z9D"
      },
      "source": [
        "# **Main Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0aTflbY7G6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ba6162-dca6-4ad6-c070-ddbd2cdee62f"
      },
      "source": [
        "print(\"\\n+=====================Execute the Training and Validation Phase=====================+\\n\\n\")\n",
        "# Step 5: Execute the Training Phase\n",
        "t = 0\n",
        "print(\"Model training....\")\n",
        "for epoch in range(number_of_epochs):\n",
        "\n",
        "    start_time = time.time()                                    # Start time when one epoch will start executing\n",
        "\n",
        "    training_loss, training_accuracy     = train(model, training_iterator, optimizer, criterion)   # Start model training\n",
        "\n",
        "    # Step 7: Execute the Validation Phase\n",
        "    validation_loss, validation_accuracy = validation(model, validation_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()                                       # End time when one epoch will end executing\n",
        "    epoch_mins, epoch_secs, elapsed_time = epoch_time(start_time, end_time)    # Calculate time consumed by one epoch (in minutes and seconds)\n",
        "    t+=elapsed_time\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTraining Loss: {training_loss:.3f}   | Training Accuracy: {training_accuracy*100:.2f}%')\n",
        "    print(f'\\tValidation Loss: {validation_loss:.3f} |  Validation Accuracy: {validation_accuracy*100:.2f}%')\n",
        "model_elapsed_mins = int(t / 60)                  # Convert time in minutes\n",
        "model_elapsed_secs = int(t - (model_elapsed_mins * 60)) # Convert time in seconds\n",
        "print(\"\\n+==========================Model Run-Time===========================+\\n\")\n",
        "print(f'\\t\\t\\tModel Run-Time: {model_elapsed_mins}m {model_elapsed_secs}s')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+=====================Execute the Training and Validation Phase=====================+\n",
            "\n",
            "\n",
            "Model training....\n",
            "Epoch: 01 | Epoch Time: 71m 36s\n",
            "\tTraining Loss: 0.147   | Training Accuracy: 96.17%\n",
            "\tValidation Loss: 0.095 |  Validation Accuracy: 97.66%\n",
            "Epoch: 02 | Epoch Time: 43m 38s\n",
            "\tTraining Loss: 0.073   | Training Accuracy: 97.90%\n",
            "\tValidation Loss: 0.074 |  Validation Accuracy: 97.91%\n",
            "\n",
            "+==========================Model Run-Time===========================+\n",
            "\n",
            "\t\t\tModel Run-Time: 115m 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ap-ixfz3VZF"
      },
      "source": [
        "# **Train Model on Training and Validation Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oNbA_Co3PDf"
      },
      "source": [
        "tr_data, te_data = TabularDataset.splits(path = drive_path,\n",
        "                                                            train       = 'train_valid_data.csv',\n",
        "                                                            test       = 'test_data.csv',\n",
        "                                                            format      = 'csv',\n",
        "                                                            fields      = [('sentence', TEXT),('tags', LABEL)],\n",
        "                                                            skip_header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJI-Fcgn3P-2"
      },
      "source": [
        "tr_iterator, te_iterator = data.BucketIterator.splits((tr_data, te_data), batch_size=32, sort_key=lambda x: len(x.sentence), repeat=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPy4bt6PPI3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60c3e54-3cd0-4160-c2e9-bccb5815fa7c"
      },
      "source": [
        "\n",
        "print(\"\\n+=====================Execute the Training Phase=====================+\\n\\n\")\n",
        "# Step 5: Execute the Training Phase\n",
        "t = 0\n",
        "model = BLSTM(input_dimension, embedding_dimension, hidden_dimension, output_dimension, word_embeddings, number_of_layers, number_of_directions)\n",
        "model.load_state_dict(torch.load(drive_path + 'best-lstm-model.pt'))\n",
        "print(\"Model training on complete data....\")\n",
        "for epoch in range(number_of_epochs):\n",
        "\n",
        "\n",
        "    start_time = time.time()                                    # Start time when one epoch will start executing\n",
        "\n",
        "    training_loss, training_accuracy     = train(model, training_iterator, optimizer, criterion)   # Start model training\n",
        "\n",
        "\n",
        "\n",
        "    end_time = time.time()                                       # End time when one epoch will end executing\n",
        "    epoch_mins, epoch_secs, elapsed_time = epoch_time(start_time, end_time)    # Calculate time consumed by one epoch (in minutes and seconds)\n",
        "    t+=elapsed_time\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTraining Loss: {training_loss:.3f}   | Training Accuracy: {training_accuracy*100:.2f}%')\n",
        "save_model(drive_path)\n",
        "model_elapsed_mins = int(t / 60)                  # Convert time in minutes\n",
        "model_elapsed_secs = int(t - (model_elapsed_mins * 60)) # Convert time in seconds\n",
        "print(\"\\n+==========================Model Run-Time===========================+\\n\")\n",
        "print(f'\\t\\t\\tModel Run-Time: {model_elapsed_mins}m {model_elapsed_secs}s')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+=====================Execute the Training Phase=====================+\n",
            "\n",
            "\n",
            "Model training on complete data....\n",
            "Epoch: 01 | Epoch Time: 35m 37s\n",
            "\tTraining Loss: 0.054   | Training Accuracy: 98.38%\n",
            "Epoch: 02 | Epoch Time: 37m 1s\n",
            "\tTraining Loss: 0.054   | Training Accuracy: 98.37%\n",
            "\n",
            "+==========================Model Run-Time===========================+\n",
            "\n",
            "\t\t\tModel Run-Time: 72m 38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7eq9ITswjkj"
      },
      "source": [
        "# **Step 8: Execute the Testing Phase**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Ok_7ubwpra"
      },
      "source": [
        "### **Step 8.2: Test Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m9OPIMEqXOP"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss     = 0      # Initialize epoch loss to 0\n",
        "    epoch_accuracy = 0      # Initialize epoch accuracy to 0\n",
        "    epoch_f1 = 0\n",
        "    model.eval()            # Start model evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "\n",
        "            text = batch.sentence\n",
        "            predictions = model(text)                # Make model predictions on data\n",
        "            #loss = criterion(predictions, batch.tags)               # Calculate loss for each batch in epoch\n",
        "\n",
        "            output_dim = predictions.shape[-1]\n",
        "            predictions = predictions.view(-1, output_dim)\n",
        "\n",
        "            trg = batch.tags.view(-1)\n",
        "\n",
        "            loss     = criterion(predictions, trg)                 # Calculate loss for each batch in epoch\n",
        "\n",
        "            accuracy = calculate_accuracy(predictions, trg)  # Calculate accuracy for each batch in epoch\n",
        "            f1_score = calculate_f1(predictions, trg)\n",
        "            epoch_loss += loss.item()                                 # Add loss for all batches, in one epoch\n",
        "            epoch_accuracy += accuracy.item()                         # Add accuracy for all batches in one epoch\n",
        "            epoch_f1+=f1_score\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator), epoch_f1 / len(iterator)  # Average loss and accuracy for one epoch and return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7jCJVmFdQZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcfbba55-c7dc-4aa7-ad5a-2ad1f67af69c"
      },
      "source": [
        "print(\"\\n+=====================Execute the Testing Phase=====================+\\n\\n\")\n",
        "# Step 8: Execute the Testing Phase\n",
        "model = BLSTM(input_dimension, embedding_dimension, hidden_dimension, output_dimension, word_embeddings, number_of_layers, number_of_directions)\n",
        "model.load_state_dict(torch.load(drive_path + 'best-lstm-model.pt'))\n",
        "\n",
        "testing_loss, testing_accuracy, testing_f1 = evaluate(model, testing_iterator, criterion)   # Start model testing\n",
        "print(f'Testing Loss: {testing_loss:.3f} | Testing Accuracy: {testing_accuracy*100:.2f}% | Testing F1 Score: {testing_f1*100:.2f}%')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "+=====================Execute the Testing Phase=====================+\n",
            "\n",
            "\n",
            "Testing Loss: 0.076 | Testing Accuracy: 97.87% | Testing F1 Score: 97.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nUHnDfXATel"
      },
      "source": [
        "# **Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_dS6_NZ_7L3"
      },
      "source": [
        "model.eval()            # Start model evaluation mode\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "  for batch in testing_iterator:\n",
        "    if i == 2:\n",
        "      break\n",
        "    else:\n",
        "      text = batch.sentence\n",
        "\n",
        "      predictions = model(text)                # Make model predictions on data\n",
        "\n",
        "      output_dim = predictions.shape[-1]\n",
        "      predictions = predictions.view(-1, output_dim)\n",
        "\n",
        "      trg = batch.tags.view(-1)\n",
        "      i = 2\n",
        "rounded_preds = (torch.softmax(predictions,dim=1)).argmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQva8Lk8oQKv"
      },
      "source": [
        "predictions = [LABEL.vocab.itos[i] for i in rounded_preds]\n",
        "labels = [LABEL.vocab.itos[i] for i in trg]\n",
        "print(\"True LABEL:\", labels[:100])\n",
        "print(\"Prediction:\", predictions[:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhJkRzLAqmPi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}